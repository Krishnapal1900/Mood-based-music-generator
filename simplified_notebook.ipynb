{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Visualizing Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths for training and testing data\n",
    "train_dir = './train/'  # Update to your local dataset path if needed\n",
    "test_dir = './test/'\n",
    "\n",
    "# Function to count images in each class for a given dataset directory\n",
    "def classes_count(path, name):\n",
    "    classes_dict = {}\n",
    "    for class_name in os.listdir(path):\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        classes_dict[class_name] = len(os.listdir(class_path))\n",
    "    return pd.DataFrame(classes_dict, index=[name]).T\n",
    "\n",
    "# Get counts for training and testing data\n",
    "train_count = classes_count(train_dir, 'Train')\n",
    "test_count = classes_count(test_dir, 'Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate train and test class counts and display\n",
    "class_counts = pd.concat([train_count, test_count], axis=1)\n",
    "class_counts.columns = ['Train', 'Test']\n",
    "class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the class distribution for the training set\n",
    "train_count.plot(kind='barh', title='Class Distribution in Training Set', legend=False)\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Classes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Count.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize = (25, 8))\n",
    "image_count = 1\n",
    "BASE_URL = '../input/fer2013/train/'\n",
    "\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "            else:\n",
    "                fig = plt.subplot(1, 7, image_count)\n",
    "                image_count += 1\n",
    "                image = cv2.imread(BASE_URL + directory + '/' + file)\n",
    "                plt.imshow(image)\n",
    "                plt.title(directory, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 48\n",
    "batch_size = 64\n",
    "train_data_path = '../input/fer2013/train/'\n",
    "test_data_path = '../input/fer2013/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor = ImageDataGenerator(\n",
    "        rescale = 1 / 255.,\n",
    "        # Data Augmentation\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,                                        \n",
    "        fill_mode='nearest',\n",
    "    )\n",
    "\n",
    "\n",
    "test_preprocessor = ImageDataGenerator(\n",
    "    rescale = 1 / 255.,\n",
    ")\n",
    "\n",
    "train_data = train_preprocessor.flow_from_directory(\n",
    "    train_data_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape,img_shape),\n",
    "    color_mode='rgb', \n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    subset='training', \n",
    ")\n",
    "\n",
    "\n",
    "test_data = test_preprocessor.flow_from_directory(\n",
    "    test_data_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape,img_shape),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Building CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_CNN_Model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #CNN1\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(img_shape, img_shape, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #CNN2\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #CNN3\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    #Output\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(7,activation='softmax'))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Model = Create_CNN_Model()\n",
    "\n",
    "CNN_Model.summary()\n",
    "\n",
    "CNN_Model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Specifying Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Callback Checkpoint\n",
    "checkpoint_path = \"CNN_Model_Checkpoint\"\n",
    "\n",
    "Checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "# Create Early Stopping Callback to monitor the accuracy\n",
    "Early_Stopping = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True, verbose=1)\n",
    "\n",
    "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning rate\n",
    "Reducing_LR = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss',\n",
    "                                                  factor=0.2,\n",
    "                                                  patience=2,\n",
    "#                                                   min_lr=0.000005,\n",
    "                                                  verbose=1)\n",
    "\n",
    "callbacks = [Early_Stopping, Reducing_LR]\n",
    "\n",
    "steps_per_epoch = train_data.n // train_data.batch_size\n",
    "validation_steps = test_data.n // test_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_history = CNN_Model.fit( train_data , validation_data= test_data , epochs=50, batch_size= batch_size,\n",
    "                            callbacks=callbacks, steps_per_epoch= steps_per_epoch, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Evaluating CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Score = CNN_Model.evaluate(test_data)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(CNN_Score[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(CNN_Score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history):\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "    epochs = range(len(history.history[\"loss\"]))\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    #plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label = \"training_loss\")\n",
    "    plt.plot(epochs, val_loss, label = \"val_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    #plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label = \"training_accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "  \n",
    "  #plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(CNN_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Predictions = CNN_Model.predict(test_data)\n",
    "\n",
    "# Choosing highest probalbilty class in every prediction \n",
    "CNN_Predictions = np.argmax(CNN_Predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **ResNet50V2 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifing new image shape for resnet\n",
    "img_shape = 224\n",
    "batch_size = 64\n",
    "train_data_path = '../input/fer2013/train/'\n",
    "test_data_path = '../input/fer2013/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor = ImageDataGenerator(\n",
    "        rescale = 1 / 255.,\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,                                        \n",
    "        fill_mode='nearest',\n",
    "    )\n",
    "\n",
    "\n",
    "test_preprocessor = ImageDataGenerator(\n",
    "    rescale = 1 / 255.,\n",
    ")\n",
    "\n",
    "train_data = train_preprocessor.flow_from_directory(\n",
    "    train_data_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape,img_shape),\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    subset='training', \n",
    ")\n",
    "\n",
    "test_data = test_preprocessor.flow_from_directory(\n",
    "    test_data_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape,img_shape),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Fine-Tuning ResNet50V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 224,224,3\n",
    "ResNet50V2 = tf.keras.applications.ResNet50V2(input_shape=(224, 224, 3),\n",
    "                                               include_top= False,\n",
    "                                               weights='imagenet'\n",
    "                                               )\n",
    "\n",
    "#ResNet50V2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all layers except last 50\n",
    "\n",
    "ResNet50V2.trainable = True\n",
    "\n",
    "for layer in ResNet50V2.layers[:-50]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_ResNet50V2_Model():\n",
    "\n",
    "    model = Sequential([\n",
    "                      ResNet50V2,\n",
    "                      Dropout(.25),\n",
    "                      BatchNormalization(),\n",
    "                      Flatten(),\n",
    "                      Dense(64, activation='relu'),\n",
    "                      BatchNormalization(),\n",
    "                      Dropout(.5),\n",
    "                      Dense(7,activation='softmax')\n",
    "                    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50V2_Model = Create_ResNet50V2_Model()\n",
    "\n",
    "ResNet50V2_Model.summary()\n",
    "\n",
    "ResNet50V2_Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Specifying Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Callback Checkpoint\n",
    "checkpoint_path = \"ResNet50V2_Model_Checkpoint\"\n",
    "\n",
    "Checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "# Create Early Stopping Callback to monitor the accuracy\n",
    "Early_Stopping = EarlyStopping(monitor = 'val_accuracy', patience = 7, restore_best_weights = True, verbose=1)\n",
    "\n",
    "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning\n",
    "Reducing_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                  factor=0.2,\n",
    "                                                  patience=2,\n",
    "#                                                   min_lr=0.00005,\n",
    "                                                  verbose=1)\n",
    "\n",
    "callbacks = [Early_Stopping, Reducing_LR]\n",
    "\n",
    "steps_per_epoch = train_data.n // train_data.batch_size\n",
    "validation_steps = test_data.n // test_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50V2_history = ResNet50V2_Model.fit(train_data ,validation_data = test_data , epochs=30, batch_size=batch_size,\n",
    "                                         callbacks = callbacks, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Evaluating ResNet50V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50V2_Score = ResNet50V2_Model.evaluate(test_data)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(ResNet50V2_Score[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(ResNet50V2_Score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(ResNet50V2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50V2_Predictions = ResNet50V2_Model.predict(test_data)\n",
    "\n",
    "# Choosing highest probalbilty class in every prediction \n",
    "ResNet50V2_Predictions = np.argmax(ResNet50V2_Predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax= plt.subplots(figsize=(15,10))\n",
    "\n",
    "cm=confusion_matrix(test_data.labels, ResNet50V2_Predictions)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted labels',fontsize=15, fontweight='bold')\n",
    "ax.set_ylabel('True labels', fontsize=15, fontweight='bold')\n",
    "ax.set_title('ResNet50V2 Confusion Matrix', fontsize=20, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Visualizing Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotion_Classes = ['Angry', \n",
    "                  'Disgust', \n",
    "                  'Fear', \n",
    "                  'Happy', \n",
    "                  'Neutral', \n",
    "                  'Sad', \n",
    "                  'Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling Test Data to show diffrent classes\n",
    "test_preprocessor = ImageDataGenerator(\n",
    "        rescale = 1 / 255.,\n",
    "    )\n",
    "\n",
    "test_generator = test_preprocessor.flow_from_directory(\n",
    "    test_data_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape,img_shape),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**CNN Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random pictures from the dataset with their labels\n",
    "\n",
    "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
    "\n",
    "Random_Img_Index = np.random.randint(0, batch_size - 1 , 10)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(25, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "\n",
    "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
    "\n",
    "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]])\n",
    "\n",
    "    Model_Prediction = np.argmax(CNN_Model.predict( tf.expand_dims(Random_Img, axis=0) , verbose=0))\n",
    "\n",
    "    ax.imshow(Random_Img)\n",
    "\n",
    "    if Emotion_Classes[Random_Img_Label] == Emotion_Classes[Model_Prediction]:\n",
    "          color = \"green\"\n",
    "    else:\n",
    "          color = \"red\"\n",
    "    ax.set_title(f\"True: {Emotion_Classes[Random_Img_Label]}\\nPredicted: {Emotion_Classes[Model_Prediction]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**ResNet50V2 Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random pictures from the dataset with their labels\n",
    "\n",
    "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
    "\n",
    "Random_Img_Index = np.random.randint(0, batch_size - 1 , 10)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(25, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "\n",
    "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
    "\n",
    "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]])\n",
    "\n",
    "    Model_Prediction = np.argmax(ResNet50V2_Model.predict( tf.expand_dims(Random_Img, axis=0) , verbose=0))\n",
    "\n",
    "    ax.imshow(Random_Img)\n",
    "\n",
    "    if Emotion_Classes[Random_Img_Label] == Emotion_Classes[Model_Prediction]:\n",
    "          color = \"green\"\n",
    "    else:\n",
    "          color = \"red\"\n",
    "    ax.set_title(f\"True: {Emotion_Classes[Random_Img_Label]}\\nPredicted: {Emotion_Classes[Model_Prediction]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Music Player**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Music_Player = pd.read_csv(\"../input/spotify-music-data-to-identify-the-moods/data_moods.csv\")\n",
    "Music_Player = Music_Player[['name','artist','mood','popularity']]\n",
    "Music_Player.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Music_Player[\"mood\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Music_Player[\"popularity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Play = Music_Player[Music_Player['mood'] =='Calm' ]\n",
    "Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
    "Play = Play[:5].reset_index(drop=True)\n",
    "display(Play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Songs Recommendations Based on Predicted Class\n",
    "def Recommend_Songs(pred_class):\n",
    "    \n",
    "    if( pred_class=='Disgust' ):\n",
    "\n",
    "        Play = Music_Player[Music_Player['mood'] =='Sad' ]\n",
    "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
    "        Play = Play[:5].reset_index(drop=True)\n",
    "        display(Play)\n",
    "\n",
    "    if( pred_class=='Happy' or pred_class=='Sad' ):\n",
    "\n",
    "        Play = Music_Player[Music_Player['mood'] =='Happy' ]\n",
    "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
    "        Play = Play[:5].reset_index(drop=True)\n",
    "        display(Play)\n",
    "\n",
    "    if( pred_class=='Fear' or pred_class=='Angry' ):\n",
    "\n",
    "        Play = Music_Player[Music_Player['mood'] =='Calm' ]\n",
    "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
    "        Play = Play[:5].reset_index(drop=True)\n",
    "        display(Play)\n",
    "\n",
    "    if( pred_class=='Surprise' or pred_class=='Neutral' ):\n",
    "\n",
    "        Play = Music_Player[Music_Player['mood'] =='Energetic' ]\n",
    "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
    "        Play = Play[:5].reset_index(drop=True)\n",
    "        display(Play)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Predicting New Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Downloading OpenCV haarcascade frontalface Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "    \n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_image(filename, img_shape = 224):\n",
    "\n",
    "    img = cv2.imread(filename)\n",
    "\n",
    "    GrayImg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(GrayImg, 1.1, 4)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        roi_GrayImg = GrayImg[ y: y + h , x: x + w ]\n",
    "        roi_Img = img[ y: y + h , x: x + w ]\n",
    "        \n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        faces = faceCascade.detectMultiScale(roi_Img, 1.1, 4)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            print(\"No Faces Detected\")\n",
    "        else:\n",
    "            for (ex, ey, ew, eh) in faces:\n",
    "                img = roi_Img[ ey: ey+eh , ex: ex+ew ]\n",
    "    \n",
    "    RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    RGBImg= cv2.resize(RGBImg,(img_shape,img_shape))\n",
    "\n",
    "    RGBImg = RGBImg/255.\n",
    "\n",
    "    return RGBImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot(filename, class_names):\n",
    "\n",
    "    # Import the target image and preprocess it\n",
    "    img = load_and_prep_image(filename)\n",
    "\n",
    "    # Make a prediction\n",
    "    pred = ResNet50V2_Model.predict(np.expand_dims(img, axis=0))\n",
    "\n",
    "    # Get the predicted class\n",
    "    pred_class = class_names[pred.argmax()]\n",
    "\n",
    "    # Plot the image and predicted class\n",
    "    #plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {pred_class}\")\n",
    "    plt.axis(False);\n",
    "    \n",
    "    Recommend_Songs(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(\"../input/fer2013/test/sad/PrivateTest_13472479.jpg\", Emotion_Classes) # with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Image to Test On\n",
    "!wget -c \"https://pbs.twimg.com/media/EEY3RFFWwAAc-qm.jpg\" -O sad.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(\"./happy.jpg\", Emotion_Classes) # with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(\"../input/fer2013/test/angry/PrivateTest_22126718.jpg\", Emotion_Classes) # with ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Image to Test On\n",
    "!wget -c \"https://pbs.twimg.com/profile_images/758370732413947904/xYB5Q3FY_400x400.jpg\" -O happy.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot(\"./sad.jpg\", Emotion_Classes) # with ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Model.save(\"CNN_Model.h5\")\n",
    "\n",
    "ResNet50V2_Model.save(\"ResNet50V2_Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 786787,
     "sourceId": 1351797,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1012989,
     "sourceId": 1708668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30301,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
